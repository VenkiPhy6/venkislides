<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<title>PPPE 6367</title>


<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><link rel="stylesheet" href="/venkislides/reveal-js/dist/reset.css">
<link rel="stylesheet" href="/venkislides/reveal-js/dist/reveal.css"><link rel="stylesheet" href="/venkislides/reveal-js/dist/theme/simple.css" id="theme">
<link rel="stylesheet" href="/venkislides/highlight-js/default.min.css">
  </head>
  <body>
    
    <div class="reveal">
      <div class="slides">
  

    <section><h2 id="estimation-of-dynamic-discrete-choice-models-in-continuous-time-with-an-application-to-retail-competition">Estimation of Dynamic Discrete Choice Models in Continuous Time with an Application to Retail Competition</h2>
<p>Peter Arcidiacono, Patrick Bayer, and Paul B Ellickson</p>
<p>April 24, 2024</p>
<p><em>For</em> PSCI 7372: Game Theory for Political Scientists</p>
</section><section>
<h2 id="whats-being-modeled-here">What&rsquo;s being modeled here?</h2>
<ul>
<li>We want to understand the heterogeneity across firm types in the competitive impacts (outcome) of Walmart&rsquo;s (player) entry (action) into a market.</li>
<li>The discrete state space, $\chi$, models the market share of each firm.
<ul>
<li>Each $x_k \in \chi$ is a vector that details the number of stores each firm has on the market.</li>
</ul>
</li>
</ul>


<span class='fragment ' ><em>How would rational players drive continuous time dynamics in such a space? This is the model here.</em></span>


</section><section>
<h2 id="players">Players</h2>
<ul>
<li>Each player indexed as $i$ is a firm in the grocery/supermarket industry. Nature indexed as $i=0$ also makes moves in the game.</li>
<li>Players ($i &gt; 0$) come in 3 types:
<ul>
<li>Chain firms, $c$ ‚õìÔ∏è</li>
<li>Fringe firms, $f$ üõçÔ∏è</li>
<li>Walmart, $w$</li>
</ul>
</li>
<li>So, the state vector is:</li>
</ul>
<p>$$x_k = \left( s^f_{1k}, s^f_{2k}, ..., s^c_{1k}, s^c_{2k}, ..., s^w_{k}, d_k \right)$$</p>
</section><section>


<section data-shortcode-section>
<h2 id="timing">Timing</h2>
<p>Two stochastic processes in continuous time drive the competition in the market.</p>
<ol>
<li>Nature pushes the competitive state of the market according to a Markov Jump Process.</li>
<li>Players move and push the competitive state of the market according to another competing Markov Jump Process.</li>
</ol>
<p>Overall, a compound Markov Jump creates the dynamics in the game.</p>
</section><section>
<h3 id="an-imperfect-but-useful-analogy---frogger">An imperfect but useful analogy - Frogger!</h3>
<img src = "./assets/large.png">
</section><section>
<h3 id="a-sufficient-definition-for-frogger">A sufficient definition for Frogger</h3>
<p>How do you define the path of jumps a frog is taking in this game? One way to do it is to assume players are rational and to define two things:</p>
<ol>
<li>For each state of the world, <strong>when</strong> does new traffic spawn and, <strong>when</strong> does the frog jump?</li>
<li>For each state of the world, <strong>where</strong> does the new traffic spawn and <strong>where</strong> does the frog jump to?</li>
</ol>
</section><section>
<h3 id="jump-hold-construction-of-a-markov-jump-process">Jump-Hold construction of a Markov Jump Process</h3>
<ol>
<li><strong>The hold</strong>: While in state $x_k$, <em>when</em> to consider jumping.</li>
<li><strong>The jump</strong>: While in state $x_k$, when considering a jump, <em>which state</em> (where) to jump to (including remaining in the same state)?</li>
</ol>
</section><section>
<h3 id="intensity-matrix-representation-of-a-markov-jump-process">Intensity Matrix representation of a Markov Jump Process</h3>
<p>$$Q = \begin{bmatrix}
q_{11} & q_{12} & \cdots & q_{1K} \\
q_{21} & q_{22} & \cdots & q_{2K} \\
\vdots & \vdots & \ddots & \vdots \\
q_{K1} & q_{K2} & \cdots & q_{KK}
\end{bmatrix}$$</p>
<ul>
<li>$q_{kl}=\lim_{h \rightarrow 0} \frac{Pr(X_{t+h}=l | X_t=k)}{h}$, the <em>hazard rate</em>.</li>
<li>Obeys <strong>Markovian</strong> property $Pr(X_{t+h}=l | X_t=k) = Pr(X_{t+h}=l | X_t =k, X_{t-1}, X_{t-2}, &hellip;)$</li>
</ul>
</section><section>
<ul>
<li>Transition probability of <strong>the jump</strong>: $p_{kl}= \frac{q_{kl}}{\sum_{l\ne k}q_{kl}}$</li>
<li>$q_{kk}=-\sum_{l\ne k}q_{kl}$ is the rate of remaining in the same state. Then <strong>the hold</strong> is given as $exp(-q_{kk})$.</li>
</ul>
</section><section>
<h3 id="compound-markov-jump-process">Compound Markov Jump Process</h3>
<ul>
<li>Nature&rsquo;s markov process matrix: Q_0</li>
<li>Move arrival process of the players (how does the frog jump?): Q_1
<ul>
<li>In Q_1, note that $q_{kk} = \lambda$, a constant for all states.</li>
<li>Transition probability is given as $\sigma_{jk}$, the probability of taking action $j$ in state $k$</li>
<li>For convenience we also define, $l(j,k)$, the function which tells us the next state when action $j$ is taken in state $k$</li>
</ul>
</li>
<li>Turns out, both these matrices can just be added up to get the compound dynamics of the whole system: $Q = Q_0 + Q_1$</li>
</ul>

</section>
</section><section>


<section data-shortcode-section>
<h2 id="utilities">Utilities</h2>
<p>There are 3 types of utility here:</p>
<ol>
<li>Flow utility, $u_{ik}$: There are just fixed costs and revenues of owning and operating a certain set of stores (i.e) for every state of the market</li>
<li>Choice-specific utility $\psi_{ijk}$: The costs and revenues of making a choice at a given state of the world
<ul>
<li>The choice set has only two discrete choices one of which can be made in each move arrival. Either open a store or close a store. $j \in J = { -1, 1 }$</li>
</ul>
</li>
<li>Choice-specific unobserved shock, $\epsilon_{ijk}$: Each firm may have some private costs/benefits from opening or closing a store we may not know about.</li>
</ol>
</section><section>
<h3 id="flow-utilities-for-chain-firms-">Flow utilities for chain firms ‚õìÔ∏è</h3>
<p>$$\begin{align}
u_{ik}^{\text{c}} = s_{ik}^{\text{c}} \left( \beta_{0}^{\text{c}} + \beta_{1}^{\text{c}} \tilde{s}_{ik}^{\text{c}} + \beta_{2}^{\text{c}} s_k^{\text{w}} + \beta_{3}^{\text{c}} s_k^{\text{f}} + \beta_{4}^{\text{c}} s_{ik}^{\text{c}} + \beta_{5}^{\text{c}} d_k + \beta_{6}^{\text{c}} z \\ + \beta_{7}^{\text{c}} z s_{ik}^{\text{c}} \right) + e_{ik}^{\text{c}}
\end{align}$$</p>
<p>where $e_{ik}^{\text{c}} = \mu_{1}^{\text{c}} s_{ik}^{\text{c}} + \mu_{2}^{\text{c}} (s_{ik}^{\text{c}})^2 + \mu_{3}^{\text{c}} (s_{ik}^{\text{c}})$</p>
</section><section>
<h3 id="choice-specific-utilities-for-chain-firms-">Choice-specific utilities for chain firms ‚õìÔ∏è</h3>
<p>$$\psi_{ijk} = \begin{cases} \eta_0^{\text{c}} + \eta_1^{\text{c}} z + \kappa_0^{\text{c}} + \kappa_1^{\text{c}} z & \text{if } s_{ik}^{\text{c}} = 0 \text{ and } j = 1, \\ \kappa_0^{\text{c}} + \kappa_1^{\text{c}} z & \text{if } s_{ik}^{\text{c}} > 0 \text{ and } j = 1, \\ \phi_0^{\text{c}} + \phi_1^{\text{c}} z & \text{if } s_{ik}^{\text{c}} > 0 \text{ and } j = -1, \\ 0 & \text{otherwise}. \end{cases}$$</p>
</section><section>
<h3 id="flow-utilities-for-fringe-firms-">Flow utilities for fringe firms üõçÔ∏è</h3>
<p>$$u_{ik}^{\text{f}} = \beta^{\text{f}}_0 + \beta^{\text{f}}_1 s_k^{\text{c}} + \beta^{\text{f}}_2 s_k^{\text{w}} + \beta^{\text{f}}_3 s_k^{\text{f}} + \beta^{\text{f}}_4 d_k + \beta^{\text{f}}_5 z + \beta^{\text{f}}_6 z s_k^{\text{f}} + e_{ik}^{\text{f}}.$$</p>
<p>where $e_{ik}^{\text{f}} = \mu^{\text{f}}_0 + \mu^{\text{f}}_1 s_k^{\text{f}} + \mu^{\text{f}}_2 (s_k^{\text{f}})^2$</p>
</section><section>
<h3 id="choice-specific-utilities-for-fringe-firms-">Choice-specific utilities for fringe firms üõçÔ∏è</h3>
<p>$$\psi_{ijk} = \begin{cases} \eta_0^{\text{f}} + \eta_1^{\text{f}} z & \text{if } s_{ik}^{\text{f}} = 0 \text{ and } j = 1, \\ 0 & \text{otherwise}. \end{cases}$$</p>

</section>
</section><section>
<h2 id="strategies">Strategies</h2>
<ul>
<li>Choice set: There discrete choices can be made in each move arrival: Open a store or close a store or do nothing: $j \in J = { -1, 0, 1 }$</li>
<li>A strategy would be, $\delta: \mathcal{X} \times \mathbb{R}^J \to \mathcal{A}$</li>
</ul>
</section><section>
<h2 id="information">Information</h2>
<ul>
<li>All the players know each other and also the rate at which their moves arrive. Obviously they all know what nature is doing.</li>
<li>Notice here that the choice-specific unobserved shock, $\epsilon_{ijk}$ are not known to other players. The other utilities of each player is known to everyone.</li>
</ul>
</section><section>
<h2 id="assumptions">Assumptions</h2>
<ul>
<li>Assumption 1. (Discrete States). The state space is finite</li>
<li>Assumption 2. (Bounded Rates and Payoffs). The discount rate‚Å†, move arrival rate, rates of state changes due to nature, and payoffs are all bounded</li>
<li>Assumption 3. (Additive Separability). For each player and in each state the instantaneous payoff associated with choice is additively separable = Choice-specific utility + Choice-specific shock</li>
</ul>
</section><section>
<ul>
<li>Assumption 4. (Distinct Actions). The payoff you get from doing nothing is nothing. For the other actions there is a clearly defined payoff and which state you would move the world towards.</li>
<li>Assumption 5. (Private Information). Choice-specific shock is iid</li>
</ul>
</section><section>


<section data-shortcode-section>
<h2 id="equilibrium-concept">Equilibrium concept</h2>
<p>Remember that the process here is Markovian. So you need equilibrium to be SPNE and so the relevant equilibrium idea here is Markov Perfect Equilibrium.</p>
<p>$$\label{eq:multi:optimal} \delta_i(k, \varepsilon_i; \varsigma_i) = j \iff \psi_{ijk} + \varepsilon_{ij} + V_{i,l(i,j,k)}(\varsigma_i) \geq \psi_{ij'k} + \varepsilon_{ij'} + V_{i,l(i,j',k)}(\varsigma_i) \quad \forall j' \in \mathcal{A}_{ik}.$$</p>
</section><section>
<h3 id="value-function">Value function</h3>
<img src = "./assets/val.png">

</section>
</section><section>
<h2 id="whats-the-equillibruim-or-equillibria">What&rsquo;s the equillibruim or equillibria?</h2>
<p>Instead of telling what actions to take, the authors characterize MPE as choice probabilities, ${ \sigma_1, \dots, \sigma_N }$ where each is a best response to given beliefs ‚Å†$\sigma_{-i}$.</p>
</section><section>
<h2 id="analysis">Analysis</h2>
<p>Brouwer&rsquo;s Theorem says with the assumptions and this setup existence is guaranteed. In fact, the authors estimate the parameters of the utility function at this equilibrium.</p>
</section><section>


<section data-shortcode-section>
<h2 id="discussion">Discussion</h2>
<h3 id="why-is-this-paper-clever">Why is this paper clever?</h3>
<p>Out of all the choices that could be made, the paper makes specific model choices so that not only does the equilibrium exist but it is also identifiable!</p>
<ul>
<li>State space was made discrete and finite.</li>
<li>Time was made continuous and infinite.</li>
<li>Dynamics were made Markovian.</li>
</ul>
</section><section>
<h3 id="where-did-that-value-function-come-from">Where did that value function come from?</h3>
<p>Here is a statement of the optimization problem in finite-state, continuous time with stochastic dynamics taken from here:</p>
<img src = "./assets/math2.png">
</section><section>
<p>Belman equation is now Hamilton-Jacobi-Bellman equation:</p>
<img src = "./assets/math3.png">
</section><section>
<p>Another way of saying a similar thing for finite-state, continuous time with deterministic dynamics:</p>
<img src = "./assets/math.jpg">

</section>
</section><section>
<h2 id="thank-you">Thank you!</h2>
<img src = "./assets/frogger_senifeld.jpg"></section>

  


</div>
      

    </div>
<script type="text/javascript" src=/venkislides/reveal-hugo/object-assign.js></script>


<script src="/venkislides/reveal-js/dist/reveal.js"></script>


  <script type="text/javascript" src="/venkislides/reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="/venkislides/reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="/venkislides/reveal-js/plugin/zoom/zoom.js"></script>
  
  <script type="text/javascript" src="/venkislides/reveal-js/plugin/notes/notes.js"></script>
  
<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }

  var revealHugoDefaults = { center: true, controls: true, history: true, progress: true, transition: "slide" };
  var revealHugoSiteParams = {};
  var revealHugoPageParams = {"theme":"simple"};

  var revealHugoPlugins = {
    
    plugins: [RevealMarkdown,RevealHighlight,RevealZoom,RevealNotes]
  };

  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams),
    camelize(revealHugoPlugins));

  Reveal.initialize(options);
</script>





  
  

  
  

  
  
    
  

  
  
    
  

  
  
    
  

  
  
    
  

  
  
    
  

  
  





<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
  

<script type="text/javascript" id="MathJax-script" async src="/venkislides/tex-svg_10887261161190234492.js"></script>

    
    
  </body>
</html>
